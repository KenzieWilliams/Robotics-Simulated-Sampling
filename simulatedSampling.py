# -*- coding: utf-8 -*-
"""
@author Mackenzie Williams
Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SCMRKkhzS6tgD2d1c1r76h13aKfXmEPA



## Introduction

In this project, we will be building a (simulated) trash sorting robot. In this scenario, the robot tries to sort trash of some pre-determined categories into corresponding bins.

**However, instead of using gtsam library, we will implement DiscreteDistribution, DiscreteConditional, and GaussianConditional classes ourselves. Please read the comments to understand each function.**

First, import some useful libraries.
"""

#export
import numpy as np
import math
from enum import Enum

# Commented out IPython magic to ensure Python compatibility.
# %load_ext autoreload
# %autoreload 2

#! pip install --upgrade --no-cache-dir gdown

get_ipython().system(' gdown --id 1lQUdlp5Olsz4G3z3svjrc9AEYsktVdZ9') #Do NOT comment out

from project1_test import TestProject1
from project1_test import verify

np.random.seed(3630)
unit_test = TestProject1()

"""**Useful Global Variables:**"""

#export
class Trash(Enum):
    CARDBOARD = 0
    PAPER = 1
    CAN = 2
    SCRAP_METAL = 3
    BOTTLE = 4

# All possible actions/bins (nop means no action)
ACTIONS = ['glass_bin', 'metal_bin', 'paper_bin', 'nop']
# Categories of trash
Category = ['cardboard', 'paper', 'can', 'scrap_metal', 'bottle']
# Two conductivity states
Conductivity = ["false", "true"]
# Detection states
Detection = ['bottle', 'cardboard', 'paper']
# Appromixations of each category given 1000 pieces of trash
Appromixation = [200, 300, 250, 200, 50]

"""**IMPORTANT NOTE: Please use the variables provided for the results of each of the TODOs.**
## Modeling the World State
- Functions to complete: **TODO 1 - TODO 4**
- Objective: Representing the prior probabilities of the trash categories and simulate it by sampling. Please use the prior probabilities provided in the textbook

**TODO 1:**

Complete DiscreteDistribution
"""

#export
# Probability distribution of a discrete variable.
class DiscreteDistribution:
  def __init__(self, prior_names, prior):
    '''
    Constructor
        Parameters:
            prior_names (list[str]): list of prior category names
            prior (list[float]): prior probablity/samples for each category
    '''
    self._names = prior_names.copy()
    self._prior = np.array(prior, dtype=float)
    self._prior /= self._prior.sum()

  def get_name_index(self, name) -> int:
    '''
    Helper function to get index of prior name
    '''
    return self._names.index(name)

  def pmf(self) -> list:
    return self._prior

  # TODO 1:
  # sample item
  def sample(self) -> int:
    '''
    Return a sample with the prior probabilities

        Parameters:
            None

        Returns:
            sampled_index (int): an int indicating the sampled item name,
                you may use the helper function to get index of a name
    '''
    sampled_index = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #THIS IS A SAMPLE SUBMISSION TO REVIEW WHAT HAS BEEN DONE; THE PROJECT IS NOT COMPLETE
    #COMPLETE GOOD TO GO
    #create a random number to simulate sampling
    import random
    rand = random.random()
    #track current sum and index in the while loop
    sum = 0
    i = 0
    #iterate through the priors until the correct range is reached
    while (i < len(self._names)):
      sum += self._prior[i]
      if (rand <= sum):
        sampled_index = i
        break
      i += 1


    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return sampled_index

"""**TODO 2 & TODO 3**:"""

#export
# TODO 2:
# Prior probabilities
def get_category_prior():
    '''
    Returns the prior probabilities of the trash categories.

        Parameters:
            None

        Returns:
            category_prior (DiscreteDistribution): a DiscreteDistribution
                that summarizes the prior probabilities of all trash categories
    '''
    category_prior = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #COMPLETE GOOD TO GO
    #I understand what a discrete distribution is but I'm confused how we're returning it (same for pmf in the following)
    #category_prior =  #are we returning the list? a DiscreteDistribution object?
    #return the object (create new)
    category_prior = DiscreteDistribution(Category, Appromixation)


    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return category_prior


# TODO 3:
# Prior probabilities PMF
def get_category_prior_pmf():
    '''
    Returns the probability mass function (PMF) of the prior probabilities
    of the trash categories.

        Parameters:
            None

        Returns:
            category_prior_pmf (list[float]): a list of the PMF
    '''
    category_prior_pmf = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #COMPLETE GOOD TO GO
    #use todo 2 to get the prior from that distribution
    category_prior_pmf = get_category_prior().pmf()

    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return list(category_prior_pmf)


"""**TODO 4**:"""

#export
# TODO 4:
def sample_category():
    '''
    Returns a sample of trash category by sampling with the prior probabilities
    of the trash categories

        Parameters:
            None

        Returns:
            sample (int): an int indicating the sampled trash category
    '''
    sample = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #wrong --test failed: None ?


    u = np.random.rand()
    cdf = [0.2, 0.5, 0.75, 0.95, 1]
    for category in range(5):
        if u<float(cdf[category]):
            return category

    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return sample

"""##
- Functions to complete: **TODO 5-7** , **TODO 8-10**
- Objective: Representing conditional probabilities of sensors and simulate them by sampling, please use the data provided in the textbook

**TODO 5 & TODO 6:**

Complete DiscreteConditional
"""

#export
# Conditional probability of P(A | B), where both A and B are discrete variables.
class DiscreteConditional:
  def __init__(self, A_names, B_names, cpt):
    '''
    Constructor
        Parameters:
            A_names (list[str]): names of possible values of A
            B_names (list[str]): names of possible values of B
            cpt (list[list[float]]): conditional probability table, represented by a 2D list
    '''
    self._B_names = B_names.copy()
    self._A_names = A_names.copy()
    self._cpt = np.array(cpt, dtype=float)
    self._cpt /= np.sum(self._cpt, axis=1)[:, np.newaxis]

  def get_A_index(self, A_name) -> int:
    return self._A_names.index(A_name)

  # TODO 5:
  # sample value of A given value of B
  def sample(self, B_index: int) -> int:
    '''
    Returns a sample of A using the conditional probability distribution
    given the value of B

        Parameters:
            B_index(int): Given value of B (represented by an index)

        Returns:
            sampled_index (int): an int indicating the sampled item name,
                you may use the helper function to get index of A
    '''
    sampled_index = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #Complete Untested
    #get random number between 0 & 1
    import random
    rand = random.random()
    #track current sum and index in the while loop
    sum = 0
    i = 0
    #iterate through the priors until the correct range is reached
    while (i < len(self._cpt[B_index])):
      sum += self._cpt[B_index][i]
      if (rand <= sum):
        sampled_index = i
        break
      i += 1
    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return sampled_index

  # TODO 6:
  # likelihoods of B given the value of A
  def likelihoods(self, A_index: int) -> list:
    '''
    Returns the likelihoods of all categories given the value of A

        Parameters:
            A_index (int): value of A (represented as an index)

        Returns:
            likelihoods (list[float] or np.ndarray): a list of likelihoods of each category
    '''
    likelihoods = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #COMPLETE UNTESTED
    #likelihood = p(T | A)
    likelihoods = self._cpt[A_index]


    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return likelihoods

"""**TODO 7 & TODO 8:**

Complete GaussianConditional
"""

#export
# Conditional probability of P(A | B), where B is a discrete
# variable, and A is a continuous variable under Gaussian distribution.
class GaussianConditional:
    def __init__(self, B_names, means, sigmas):
      '''
      Constructor
          Parameters:
              B_names (list[str]): list of prior category names
              means (list[float]): list of mean measurement given each category
              sigmas (list[float]): list of measurement standard deviation given each category
      '''
      self._B_names = B_names.copy()
      self._means = means
      self._sigmas = sigmas

    @staticmethod
    def Gaussian(x, mu=0.0, sigma=1.0):
      return np.exp(-0.5 * (x - mu) ** 2 / sigma ** 2) / np.sqrt(2 * np.pi * sigma ** 2)

    # TODO 7:
    # sample A given B
    def sample(self, B_index):
        '''
        Returns a sample of weight using the conditional probability given
        the prior name index.

            Parameters:
                B_index (int): given value of B (represented by an index)

            Returns:
                weight (float): a float indicating the sampled weight
        '''
        weight = None
        ###############################################################################
        #                             START OF YOUR CODE                              #
        ###############################################################################
        #COMPLETE UNTESTED
        #get random number between 0 & 1
        mean = self._means[B_index]
        sigma = self._sigmas[B_index]
        weight = np.random.normal(mean, sigma)


        ###############################################################################
        #                              END OF YOUR CODE                               #
        ###############################################################################
        return weight

    # TODO 8:
    # likelihoods of A given B
    def likelihoods(self, B_value: float) -> list:
      '''
      Returns the likelihoods of A given B

          Parameters:
              B_value (float): a float indicating the value of B

          Returns:
              likelihoods (list[float] or np.ndarray): a list of likelihoods of A
      '''
      likelihoods = None
      ###############################################################################
      #                             START OF YOUR CODE                              #
      ###############################################################################
      i = 0
      likelihoods = []
      while (i < len(self._B_names)):
        likelihoods.append(self.Gaussian(B_value, self._means[i], self._sigmas[i]))
        i += 1

      ###############################################################################
      #                              END OF YOUR CODE                               #
      ###############################################################################
      return likelihoods

"""**TODO 9 - TODO 11**:

Declare conditional objects for sensor data
"""

#export
# TODO 9:
# 1. Conductivity - binary sensor
def get_pCT():
    '''
    Returns P(Conductivity | Trash Category)

        Parameters:
            None

        Returns:
            pCT (DiscreteConditional): a DiscreteConditional that
                indicates the conditinal probability of conductivity given
                the trash category
    '''
    pCT = None
    prob_distribution = []
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #COMPLETE UNTESTED
    trash_cats = Category
    cond_values = ['false', 'true']
    prob_distribution = [[0.99, 0.99, 0.1, 0.15, 0.95],[0.01, 0.01, 0.9, 0.85, 0.05]]
    pCT = DiscreteConditional(trash_cats, cond_values, prob_distribution)

    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return pCT


# TODO 10:
# 2. Detection - multi-valued sensor
def get_pDT():
    '''
    Returns P(Detection | Trash Category)

        Parameters:
            None

        Returns:
            pDT (DiscreteConditional): a DiscreteConditional that
                indicates the conditinal probability of camera detection
                given the trash category
    '''
    pDT = None
    prob_distribution = []
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #COMPLETE UNTESTED
    det_values = ['bottle', 'cardboard', 'paper']
    prob_distribution = [[0.02, 0.02, 0.33, 0.33, 0.95],[0.88, 0.2, 0.33, 0.33, 0.02], [0.1, 0.78, 0.34, 0.34, 0.03]]
    pDT = DiscreteConditional(Category, det_values, prob_distribution)

    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return pDT

# TODO 11:
# 3. Weight - continuous-valued sensor
def get_pWT():
    '''
    Returns P(Weight | Trash Category)

        Parameters:
            None

        Returns:
            pWT (GaussianConditional): a GaussianConditional object which represents
            prior name, mean, and sigma of each category for Gaussian distribution
    '''
    pWT = None
    means = []
    sigmas = []
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #COMPLETE - Untested WHY is this OR sample_weight wrong?
    means = [20, 5, 15, 150, 300]
    sigmas = [10, 5, 5, 100, 200]
    pWT = GaussianConditional(Category, means, sigmas)

    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return pWT

"""**TODO 12:**"""

#export
# TODO 12:
def sample_conductivity(category=None):
    '''
    Returns a sample of conductivity using the conditional probability
    given the trash category.
    If the category parameter is None, sample a category first.

        Parameters:
            category (int): an int indicating the trash category

        Returns:
            conductivity (int): an int indicating the conductivity, with
                0 being nonconductive and 1 being conductive
    '''
    conductivity = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #COMPLETE GOOD TO GO
    # sample from category
    conductivity = True
    if (category == None):
      category = DiscreteDistribution.sample
    import random
    rand = random.random()
    if (category == 0 and rand <= 0.99):
      conductivity = False
    elif (category == 1 and rand <= 0.99):
      conductivity = False
    elif (category == 2 and rand <= 0.1):
      conductivity = False
    elif (category == 3 and rand <= 0.15):
      conductivity = False
    elif (category == 4 and rand <= 0.95):
      conductivity = False



    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return conductivity

"""**TODO 13**:"""

#export
# TODO 13:
def sample_detection(category=None):
    '''
    Returns a sample of detection using the conditional probability given
    the trash category.
    If the category parameter is None, sample a category first.

        Parameters:
            category (int): an int indicating the trash category

        Returns:
            detection (int): an int indicating the sampled detection
    '''
    detection = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #COMPLETE GOOD TO GO
    import random
    rand = random.random()
    if (category == None):
      category = DiscreteDistribution.sample
    detection = 2
    if ((category == 0 or category == 1) and rand <= 0.02):
      detection = 0
    elif ((category == 2 or category == 3) and rand <= 0.33):
      detection = 0
    elif (category == 4 and rand <= .95):
      detection = 0
    elif (category == 0 and rand <= .9):
      detection = 1
    elif (category == 1 and rand <= 0.22):
      detection = 1
    elif ((category == 2 or category == 3) and rand <= 0.66):
      detection = 1
    elif (category == 4 and rand <= 0.97):
      detection = 1


    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return detection


"""**TODO 14**:"""

#export
# TODO 14:
def sample_weight(category=None):
    '''
    Returns a sample of weight using the conditional probability given
    the trash category.
    If the category parameter is None, sample a category first.

        Parameters:
            category (int): an int indicating the trash category

        Returns:
            weight (float): a float indicating the sampled weight
    '''
    weight = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #wrong WHY is this OR get_pWT wrong?
    #get the sample
    if category == None:
      category = sample_category()
    pWC = get_pWT()
    weight = pWC.sample(category)


    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return weight

print("Testing your sample weight: ", verify(unit_test.test_sample_weight, sample_weight))

"""## 
- Functions to complete: **TODO 15-19**
- Objective: Calculating likelihoods using different methods given the observations from the world, please use the data provided in the textbook

**TODO 15**:
"""

#export
# TODO 15:
def likelihood_no_sensors():
    '''
    Returns the likelihoods of all trash categories using only priors,
    aka no sensors.

        Parameters:
            None

        Returns:
            likelihoods (list[float]): a list of likelihoods of each trash category
    '''
    likelihoods = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #COMPLETE GOOD TO GO
    likelihoods = get_category_prior_pmf()



    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return likelihoods


"""**TODO 16**:"""

#export
# TODO 16:
def likelihood_given_weight(weight):
    '''
    Returns the likelihoods of all trash categories using only the weight
    sensor (no priors)

        Parameters:
            weight (float): a float indicating the weight of trash

        Returns:
            likelihoods (list[float] or np.ndarray): a list of likelihoods of each trash category
    '''
    likelihoods = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #COMPLETE UNTESTED (NEED pWT TO BE DONE)
    likelihoods = get_pWT().likelihoods(weight)


    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return likelihoods


"""**TODO 17**:"""

#export
# TODO 17:
def likelihood_given_detection(detection):
    '''
    Returns the likelihoods of all trash categories using only the detection
    sensor (no priors)

        Parameters:
            detection (int): an int indicating the sampled detection

        Returns:
            likelihoods (list[float] or np.ndarray): a list of likelihoods of each trash category
    '''
    likelihoods = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #NOT DONE
    #use a likelihood that i already made (Todo 6 under discrete conditional)
    #make a discrete conditional with A_names B_names and a cpt
    #i WANT to just use the line below, but the normalized likelihood isn't passing
    #likelihoods = get_pDT().likelihoods(detection)
    if (detection == 0):
      likelihoods = [0.02, 0.02, 0.33, 0.33, 0.95]
    elif (detection == 1):
      likelihoods = [0.88, 0.2, 0.33, 0.33, 0.02]
    else:
      likelihoods = [0.1, 0.78, 0.34, 0.34, 0.03]


    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return likelihoods


"""**TODO 18**:"""

#export
# TODO 18:
def bayes_given_weight(weight):
    '''
    Returns the posteriors of all trash categories by combining the weight
    sensor and the priors

        Parameters:
            weight (float): a float indicating the weight of the trash

        Returns:
            posteriors (list[float] or np.ndarray): a list of posterior probabilities of each trash category
    '''
    posteriors = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #NOT DONE
    #Bayes = (likelihood * prior) then normalize
    posteriors = []
    likelihood = likelihood_given_weight(weight)
    prior = get_category_prior_pmf()
    i = 0
    sum = 0
    while (i < len(prior)):
      posteriors.append(likelihood[i] * prior[i])
      sum += posteriors[i]
      i += 1
    j = 0
    while (j < len(posteriors)):
      posteriors[j] /= sum
      j += 1


    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return posteriors


"""**TODO 19:**"""

#export
# TODO 19:
# Bayes with three sensors
def bayes_given_three_sensors(conductivity, detection, weight):
    '''
    Returns the posteriors of all trash categories by combining all three
    sensors and the priors

        Parameters:
            conductivity (int): an int indicating the conductivity, with
                0 being nonconductive and 1 being conductive

            detection (int): an int indicating the sampled detection

            weight (float): a float indicating the weight of the trash

        Returns:
            posteriors (list[float] or np.ndarray): a list of posterior probabilities of each trash category
    '''
    posteriors = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #NOT DONE
    #Question: How do we calculate posteriors of multiple? I know how to code but I'm not sure *what* I'm coding.
    posteriors = []
    prior = get_category_prior_pmf()

    conductivity_factor = get_pCT().likelihoods(conductivity)
    detection_factor = get_pDT().likelihoods(detection)
    weight_factor = get_pWT().likelihoods(weight)
    likelihood = conductivity_factor * detection_factor * weight_factor

    i = 0
    sum = 0
    while (i < len(prior)):
      posteriors.append(likelihood[i] * prior[i])
      sum += posteriors[i]
      i += 1
    j = 0
    while (j < len(posteriors)):
      posteriors[j] /= sum
      j += 1
    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return posteriors


"""## Decision Theory 
- Functions to complete: **TODO 20**
- Objective: Incorporating the cost table with the perception to reach a final sorting decision
"""

# Cost table for each state
COST_TABLE = np.array([[2,  2,  4,  6,  0],
                       [1,  1,  0,  0,  2],
                       [0,  0,  5, 10,  3],
                       [1,  1,  1,  1,  1]])

"""**TODO 20**:"""

#export
# TODO 20:
### DECISION ###
def make_decision(posteriors):
    '''
    Returns the decision made by the robot given the likelihoods/posteriors you calculated

        Parameters:
            posteriors (list[float]): a list of posteriors of each trash category

        Returns:
            action (int): an int indicating the action taken by the robot
    '''
    action = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #NOT DONE
    expected_cost = COST_TABLE @ posteriors
    action = np.argmin(expected_cost)

    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return action


"""## 
A Gaussian distribution, also known as a normal distribution, is an inappropriate distribution to represent
the weight of an item. This is because it has an infinite range and therefore sampling from it can produce
a negative number, while an item cannot have a negative weight. A more commonly used distribution
used to represent weight is the [log-normal distribution].
- Functions to complete: **TODO 21**
- Objective: Fit a Log-Normal Distribution to a set of data
- Hint: There is an estimation of parameters section on the wikipedia article

**TODO 21**:
"""

#export
# TODO 21
def fit_log_normal(data):
    '''
    Returns mu, sigma for a log-normal distribution

        Parameters:
            data (list[float]): A list of positive floats that represent the weight of an item

        Returns:
            mu (float), sigma (float): The mu and sigma for a log-normal distribution
    '''
    mu = None
    sigma = None
    ###############################################################################
    #                             START OF YOUR CODE                              #
    ###############################################################################
    #NOT DONE
    i = 0
    sum = 0
    while (i < len(data)):
      sum += np.log(data[i])
      i += 1
    mu = sum / len(data)
    sigma_sum = 0
    j = 0
    while (j < len(data)):
      sigma_sum += ((np.log(data[j]) - mu) ** 2)
      j += 1
    variance = sigma_sum / (len(data) - 1)
    sigma = math.sqrt(variance)



    ###############################################################################
    #                              END OF YOUR CODE                               #
    ###############################################################################
    return mu, sigma